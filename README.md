# ğŸŒ Web Scraping

In this project I will dive deep into  **web scraping with Python**. where I will be exploring foundational libraries like `requests` and `BeautifulSoup`, as well as advanced libraries and frameworks like `Selenium` and `Scrapy`. Along the way, I will learn the  key methods and concepts that will make the scraping websites easier and more faster.

---

## ğŸ“š Libraries Covered

- **Requests**: For making HTTP requests and handling responses.  
- **BeautifulSoup**: For parsing and navigating HTML content.  
- **Selenium**: For automating browsers, handling dynamic content, and interacting with JavaScript-heavy sites.  
- **Scrapy**: A powerful framework for large-scale web scraping with asynchronous support and built-in project management.

---

## ğŸ” Key Concepts and Methods Learned

### 1ï¸âƒ£ Requests Library
- **HTTP Methods**: `GET` for retrieving web pages.  
- **Status Codes**:  
  - `200` â†’ Success  
  - `404` â†’ Not Found  
  - `403` â†’ Forbidden  
  - `500` â†’ Server Error  
- **Response Attributes**:  
  - `response.content` â†’ Raw binary content  
  - `response.text` â†’ Decoded text content  
  - `response.headers` â†’ Metadata about the response  
  - `response.cookies` â†’ Cookies sent by the server  
  - `response.elapsed` â†’ Time taken for the server to respond  

---

### 2ï¸âƒ£ BeautifulSoup Library
- **HTML Parsing**: Use `html.parser` to parse HTML content.  
- **Objects in BeautifulSoup**:  
  - **Tags** â†’ Represents HTML tags like `<p>` or `<a>`  
  - **NavigableString** â†’ Text content inside tags  
  - **Comment** â†’ HTML comments  
  - **ResultSet** â†’ Collection of matching elements (e.g., all paragraphs)  
- **Key Methods**:  
  - `find_all()` â†’ Find all matching elements based on tags or attributes  
  - `prettify()` â†’ Format HTML for readability  
  - `.text` â†’ Extract text inside a tag  
  - `find()` â†’ Retrieve the first matching element  

---

### 3ï¸âƒ£ Selenium Library
- **Browser Automation**: Open pages, click buttons, scroll, fill forms.  
- **Dynamic Content Handling**: Works with JavaScript-rendered sites.  
- **Key Methods**:  
  - `driver.get(url)` â†’ Open a webpage  
  - `driver.find_element_by_*()` â†’ Locate elements  
  - `driver.click()` â†’ Click buttons or links  
  - `driver.quit()` â†’ Close the browser  

---

### 4ï¸âƒ£ Scrapy Framework
- **Purpose**: Efficiently scrape large datasets and multiple pages asynchronously.  
- **Features**:  
  - Manages requests, retries, and rate limits  
  - Organizes scraping projects with spiders  
  - Handles pipelines for storing and cleaning data  

---
